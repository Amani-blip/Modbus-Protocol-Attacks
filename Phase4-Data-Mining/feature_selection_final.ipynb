{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4 Data Mining\n",
    "In this notebook we use machine learning to analyze the detection of each of the Modbus Protocol attacks: \n",
    "- Arp-based Man in the Middle (mitm)\n",
    "- TCP SYN flooding\n",
    "- Modbus Query flood\n",
    "- Ping flooding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "# Suppress User Warning messages\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets and concatenating them into one df\n",
    "files = ['clean.csv', 'mitm.csv', 'modbusQuery2Flooding.csv', 'modbusQueryFlooding.csv', 'pingFloodDDos.csv', 'tcpSYNFlood.csv']\n",
    "data = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)\n",
    "\n",
    "\n",
    "relevant_features = ['Length',\n",
    "                    'Protocol',\n",
    "                    'SYNFlag',\n",
    "                    'ACKFlag',\n",
    "                    'TimeDelta',\n",
    "                    'RelativeTime', \n",
    "                    'AttackName']\n",
    "\n",
    "data = data[relevant_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'AttackName' after mapping: [1 2 3 4 5 6]\n",
      "Non-null values in 'AttackName' after mapping: 6889976\n",
      "Null values in 'AttackName': 0\n"
     ]
    }
   ],
   "source": [
    "# mapping dictionary, using label encoding to convert the attack names to integers\n",
    "attack_name_mapping = {\n",
    "    'Clean': 1,  \n",
    "    'mitm': 2,\n",
    "    'modbusQuery2Flooding': 3,\n",
    "    'modbusQueryFlooding': 4,\n",
    "    'pingFloodDDoS': 5,\n",
    "    'tcpSYNFloodDDoS': 6\n",
    "}\n",
    "\n",
    "# Apply the mapping\n",
    "data['AttackName'] = data['AttackName'].map(attack_name_mapping)\n",
    "\n",
    "# Check the results of the mapping\n",
    "print(\"Unique values in 'AttackName' after mapping:\", data['AttackName'].unique())\n",
    "print(\"Non-null values in 'AttackName' after mapping:\", data['AttackName'].notnull().sum()) # total number of rows in 'AttackName' column that don't have null values\n",
    "print(\"Null values in 'AttackName':\", data['AttackName'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the categorical features\n",
    "categorical_features = ['Protocol', 'SYNFlag', 'ACKFlag']\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_features:\n",
    "    data[col] = label_encoder.fit_transform(data[col].astype(str)) # convert the column value to string before encoding\n",
    "\n",
    "# Impute missing values for the rest of the dataset\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# Convert all columns to numeric\n",
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = data.drop(['AttackName'], axis=1)  \n",
    "y = data['AttackName'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.34395187e+05 2.47506960e+05 8.10151768e+04 1.46548656e+06\n",
      " 5.09698962e-02 6.74046217e+05]\n",
      "[0 1 2 3 5]\n",
      "Length\n",
      "Protocol\n",
      "SYNFlag\n",
      "ACKFlag\n",
      "RelativeTime\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "selector = SelectKBest(score_func=f_regression, k=5)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_indices = selector.get_support(indices=True)\n",
    "print(selector.scores_)\n",
    "featuresArr = [];\n",
    "print(selected_indices)\n",
    "for col in data.columns:\n",
    "    featuresArr.append(col);\n",
    "for i in selected_indices:\n",
    "    print(featuresArr[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
